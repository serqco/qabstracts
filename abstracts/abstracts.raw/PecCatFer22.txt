Software testing and Android applications: a large-scale empirical study.

These days, over three billion users rely on mobile applications (a.k.a. apps) on a daily
basis to access high-speed connectivity and all kinds of services it enables, from social to
emergency needs.
{{}}
Having high-quality apps is therefore a vital requirement for developers to
keep staying on the market and acquire new users.
{{}}
For this reason, the research community
has been devising automated strategies to better test these applications.
{{}}
Despite the effort
spent so far, most developers write their test cases manually without the adoption of any
tool.
{{}}
Nevertheless, we still observe a lack of knowledge on the quality of these manually
written tests:
{{}}
an enhanced understanding of this aspect may provide evidence-based findings
on the current status of testing in the wild and point out future research directions to better
support the daily activities of mobile developers.
{{}}
We perform a large-scale empirical study
targeting 1,693 open-source Android apps and aiming at assessing (1) the extent to which
these apps are actually tested, (2) how well-designed are the available tests, (3) what is
their effectiveness, and (4) how well manual tests can reduce the risk of having defects in
production code.
{{}}
In addition, we conduct a focus group with 5 Android testing experts to
discuss the findings achieved and gather insights into the next research avenues to undertake.
{{}}
The key results of our study show Android apps are poorly tested and the available tests have
low (i) design quality, (ii) effectiveness, and (iii) ability to find defects in production code.
{{}}
Among the various suggestions, testing experts report the need for improved mechanisms
to locate potential defects and deal with the complexity of creating tests that effectively
exercise the production code.
{{}}
---
