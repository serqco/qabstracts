CLEAR: Contrastive Learning for API Recommendation.

Automatic API recommendation has been studied for years.
{{}}
There
are two orthogonal lines of approaches for this task, i.e., information-
retrieval-based (IR-based) and neural-based methods.
{{}}
Although
these approaches were reported having remarkable performance,
our observation shows that existing approaches can fail due to
the following two reasons:
{{}}
1) most IR-based approaches treat task
queries as bag-of-words and use word embedding to represent
queries, which cannot capture the sequential semantic information.
{{}}
2) both the IR-based and the neural-based approaches are weak
at distinguishing the semantic difference among lexically similar
queries.
{{}}
In this paper, we propose CLEAR, which leverages BERT sen-
tence embedding and contrastive learning to tackle the above two is-
sues.
{{}}
Specifically, CLEAR embeds the whole sentence of queries and
Stack Overflow (SO) posts with a BERT-based model rather than the
bag-of-word-based word embedding model, which can preserve the
semantic-related sequential information.
{{}}
In addition, CLEAR uses
contrastive learning to train the BERT-based embedding model for
learning precise semantic representation of programming termi-
nologies regardless of their lexical information.
{{}}
CLEAR also builds
a BERT-based re-ranking model to optimize its recommendation
results.
{{}}
Given a query, CLEAR first selects a set of candidate SO
posts via the BERT sentence embedding-based similarity to reduce
search space.
{{}}
CLEAR further leverages a BERT-based re-ranking
model to rank candidate SO posts and recommends the APIs from
the ranked top SO posts for the query.
{{}}
Our experiment results on three different test datasets confirm
the effectiveness of CLEAR for both method-level and class-level
API recommendation.
{{}}
Compared to the state-of-the-art API recom-
mendation approaches, CLEAR improves the MAP by 25%-187% at
method-level and 10%-100% at class-level.
{{}}
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page.
{{}}
Copyrights for components of this work owned by others than ACM
must be honored.
{{}}
Abstracting with credit is permitted.
{{}}
To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee.
{{}}
Request permissions from permissions@acm.org.
{{}}
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Association for Computing Machinery.
{{}}
ACM ISBN 978-1-4503-9221-1/22/05.
{{}}
.
{{}}
. $
{{}}
15.00
https://doi.org/10.1145/3510003.3510159
{{}}
---
