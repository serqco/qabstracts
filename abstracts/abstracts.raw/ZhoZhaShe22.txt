Adversarial Robustness of Deep Code Comment Generation.

Deep neural networks (DNNs) have shown remarkable performance in a variety of domains such as computer vision, speech recognition, and natural language processing.
{{}}
Recently they also have been applied to
various software engineering tasks, typically involving processing source code.
{{}}
DNNs are well-known to be
vulnerable to adversarial examples, i.e., fabricated inputs that could lead to various misbehaviors of the DNN
model while being perceived as benign by humans.
{{}}
In this paper, we focus on the code comment generation
task in software engineering and study the robustness issue of the DNNs when they are applied to this task.
{{}}
We propose ACCENT (Adversarial Code Comment gENeraTor), an identifier substitution approach to
craft adversarial code snippets, which are syntactically correct and semantically close to the original code
snippet, but may mislead the DNNs to produce completely irrelevant code comments.
{{}}
In order to improve
the robustness, ACCENT also incorporates a novel training method, which can be applied to existing code
comment generation models.
{{}}
We conduct comprehensive experiments to evaluate our approach by attacking the mainstream encoder-decoder architectures on two large-scale publicly available datasets.
{{}}
The results
show that ACCENT efficiently produces stable attacks with functionality-preserving adversarial examples,
and the generated examples have better transferability compared with the baselines.
{{}}
We also confirm, via
experiments, the effectiveness in improving model robustness with our training method.
{{}}
---
