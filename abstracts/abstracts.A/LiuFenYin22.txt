DeepState: Selecting Test Suites to Enhance the Robustness of Recurrent Neural Networks.

Deep Neural Networks (DNN) have achieved tremendous success
in various software applications.
{{}}
However, accompanied by out-
standing effectiveness, DNN-driven software systems could also
exhibit incorrect behaviors and result in some critical accidents
and losses.
{{}}
The testing and optimization of DNN-driven software
systems rely on a large number of labeled data that often require
many human efforts, resulting in high test costs and low efficiency.
{{}}
Although plenty of coverage-based criteria have been proposed to
assist in the data selection of convolutional neural networks, it is
difficult to apply them on Recurrent Neural Network (RNN) models
due to the difference between the working nature.
{{}}
In this paper, we propose a test suite selection tool DeepState
towards the particular neural network structures of RNN models
for reducing the data labeling and computation cost.
{{}}
DeepState
selects data based on a stateful perspective of RNN, which identifies
the possibly misclassified test by capturing the state changes of
neurons in RNN models.
{{}}
We further design a test selection method
to enable testers to obtain a test suite with strong fault detection
and model improvement capability from a large dataset.
{{}}
To evalu-
ate DeepState, we conduct an extensive empirical study on pop-
ular datasets and prevalent RNN models containing image and
text processing tasks.
{{}}
The experimental results demonstrate that
DeepState outperforms existing coverage-based techniques in se-
lecting tests regarding effectiveness and the inclusiveness of bug
cases.
{{}}
Meanwhile, we observe that the selected data can improve
the robustness of RNN models effectively.
{{}}
∗ Yang
Feng is the corresponding author.
{{}}
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page.
{{}}
Copyrights for components of this work owned by others than the
author(s) must be honored.
{{}}
Abstracting with credit is permitted.
{{}}
To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee.
{{}}
Request permissions from permissions@acm.org.
{{}}
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
{{}}
Publication rights licensed to ACM.
{{}}
ACM ISBN 978-1-4503-9221-1/22/05.
{{}}
.
{{}}
. $
{{}}
15.00
https://doi.org/10.1145/3510003.3510231
{{}}
---
