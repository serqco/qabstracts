Evaluating and Improving Neural Program-Smoothing-based Fuzzing.

Fuzzing nowadays has been commonly modeled as an optimization
problem, e.g., maximizing code coverage under a given time budget
via typical search-based solutions such as evolutionary algorithms.
{{}}
However, such solutions are widely argued to cause inefficient
computing resource usage, i.e., inefficient mutations.
{{}}
To address
this issue, two neural program-smoothing-based fuzzers, Neuzz
and MTFuzz, have been recently proposed to approximate pro-
gram branching behaviors via neural network models, which input
byte sequences of a seed and output vectors representing program
branching behaviors.
{{}}
Moreover, assuming that mutating the bytes
with larger gradients can better explore branching behaviors, they
develop strategies to mutate such bytes for generating new seeds
as test cases.
{{}}
Meanwhile, although they have been shown to be
effective in the original papers, they were only evaluated upon a
limited dataset.
{{}}
In addition, it is still unclear how their key tech-
nical components and whether other factors can impact fuzzing
performance.
{{}}
To further investigate neural program-smoothing-
based fuzzing, we first construct a large-scale benchmark suite
with a total of 28 popular open-source projects.
{{}}
Then, we exten-
sively evaluate Neuzz and MTFuzz on such benchmarks.
{{}}
The eval-
uation results suggest that their edge coverage performance can
be unstable.
{{}}
Moreover, neither neural network models nor muta-
tion strategies can be consistently effective, and the power of their
gradient-guidance mechanisms have been compromised.
{{}}
Inspired
† Mingyuan Wu is also affiliated with the Research Institute of Trustworthy Au-
tonomous Systems, Shenzhen, China.
{{}}
* Yuqun Zhang is the corresponding author.
{{}}
He is also affiliated with the Research
Institute of Trustworthy Autonomous Systems, Shenzhen, China and Guangdong
Provincial Key Laboratory of Brain-inspired Intelligent Computation, China.
{{}}
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page.
{{}}
Copyrights for components of this work owned by others than ACM
must be honored.
{{}}
Abstracting with credit is permitted.
{{}}
To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee.
{{}}
Request permissions from permissions@acm.org.
{{}}
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Association for Computing Machinery.
{{}}
ACM ISBN 978-1-4503-9221-1/22/05.
{{}}
.
{{}}
. $
{{}}
15.00
https://doi.org/10.1145/3510003.3510089
{{}}
---
