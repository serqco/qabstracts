On the Reliability of Coverage-Based Fuzzer Benchmarking.

Given a program where none of our fuzzers finds any bugs, how do
we know which fuzzer is better?
{{}}
In practice, we often look to code
coverage as a proxy measure of fuzzer effectiveness and consider
the fuzzer which achieves more coverage as the better one.
{{}}
Indeed, evaluating 10 fuzzers for 23 hours on 24 programs, we
find that a fuzzer that covers more code also finds more bugs.
{{}}
There
is a very strong correlation between the coverage achieved and the
number of bugs found by a fuzzer.
{{}}
Hence, it might seem reasonable
to compare fuzzers in terms of coverage achieved, and from that
derive empirical claims about a fuzzer’s superiority at finding bugs.
{{}}
Curiously enough, however, we find no strong agreement on
which fuzzer is superior if we compared multiple fuzzers in terms
of coverage achieved instead of the number of bugs found.
{{}}
The
fuzzer best at achieving coverage, may not be best at finding bugs.
{{}}
ACM Reference Format:
{{}}
Marcel Böhme, László Szekeres, and Jonathan Metzman.
{{}}
2022.
{{}}
On the Relia-
bility of Coverage-Based Fuzzer Benchmarking.
{{}}
In 44th International Confer-
ence on Software Engineering (ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA.
{{}}
ACM, New York, NY, USA, 13 pages.
{{}}
https://doi.org/10.1145/3510003.3510230
1
In the recent decade, fuzzing has found widespread interest.
{{}}
In
industry, we have large continuous fuzzing platforms employing
100k+ machines for automatic bug finding [23, 24, 46].
{{}}
In academia,
in 2020 alone, almost 50 fuzzing papers were published in the top
conferences for Security and Software Engineering [62].
{{}}
Imagine, we have several fuzzers available to test our program.
{{}}
Hopefully, none of them finds any bugs.
{{}}
If indeed they don’t, we
might have some confidence in the correctness of the program.
{{}}
Then again, even a perfectly non-functional fuzzer would find no
bugs in our program.
{{}}
So, how do we know which fuzzer has the
highest “potential” of finding bugs?
{{}}
A widely used proxy measure
of fuzzer effectiveness is the code coverage that is achieved.
{{}}
After
all, a fuzzer cannot find bugs in code that it does not cover.
{{}}
Indeed, in our experiments we identify a very strong positive
correlation between the coverage achieved and the number of bugs
found by a fuzzer.
{{}}
Correlation assesses the strength of the associa-
tion between two random variables or measures.
{{}}
We conduct our
empirical investigation on 10 fuzzers × 24 C programs × 20 fuzzing
campaigns of 23 hours (≈ 13 CPU years).
{{}}
We use three measures of
coverage and two measures of bug finding, and our results suggest:
{{}}
As the fuzzer covers more code, it also discovers more bugs.
{{}}
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page.
{{}}
Copyrights for third-party components of this work must be honored.
{{}}
For all other uses, contact the owner/author(s).
{{}}
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
{{}}
ACM ISBN 978-1-4503-9221-1/22/05.
{{}}
https://doi.org/10.1145/3510003.3510230
{{}}
---
