An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models.

Software analytics have empowered software organisations to support a wide range of improved decision-making and
policy-making.
{{background}}
However, such predictions made by software analytics to date have not been explained and justified.
{{background}}
Specifically, current
defect prediction models still fail to explain why models make such a prediction and fail to uphold the privacy laws in terms of the
requirement to explain any decision made by an algorithm.
{{background}}
In this paper, we empirically evaluate three model-agnostic techniques, i.e.,
two state-of-the-art Local Interpretability Model-agnostic Explanations technique (LIME) and BreakDown techniques, and our
improvement of LIME with Hyper Parameter Optimisation (LIME-HPO).
{{objective}}
Through a case study of 32 highly-curated defect datasets that
span across 9 open-source software systems, we conclude that (1) model-agnostic techniques are needed to explain individual
predictions of defect models; (2) instance explanations generated by model-agnostic techniques are mostly overlapping (but not exactly
the same) with the global explanation of defect models and reliable when they are re-generated; (3) model-agnostic techniques take
less than a minute to generate instance explanations; and (4) more than half of the practitioners perceive that the contrastive
explanations are necessary and useful to understand the predictions of defect models.
{{method,conclusion,result}}
Since the implementation of the studied
model-agnostic techniques is available in both Python and R, we recommend model-agnostic techniques be used in the future.
{{conclusion}}
---
